{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "spark = SparkSession.builder.appName('Iteration4').getOrCreate()\n",
    "\n",
    "databases_path = '../datasets/'\n",
    "PATH_IMAGES = '../tex/iterations/iteration_4/images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramesCSV(enum.Enum):\n",
    "    ALCOHOL_CONSUMPTION_CSV = f\"{databases_path}4_total-alcohol-consumption-per-capita-litres-of-pure-alcohol.csv\"\n",
    "    COUNTRY_MASTER_CSV = f\"{databases_path}0_master_country_codes.csv\"\n",
    "    WHO_OBESITY_CSV = f\"{databases_path}1_who_obesity.csv\"\n",
    "    MEAT_CONSUMPTION_CSV = f\"{databases_path}2_meat_consumption.csv\"\n",
    "    HUNGER_CSV = f\"{databases_path}5_global_hunger_index.csv\"\n",
    "    SMOKING_CSV = f\"{databases_path}6_share-of-adults-who-smoke.csv\"\n",
    "    HAPPINESS_REPORT_CSV = f\"{databases_path}3_happiness_report.csv\"\n",
    "\n",
    "class DataFramePreviousFieldNameOptions(enum.Enum):\n",
    "    IS_NULL = 'isnull'\n",
    "    D_TYPES = 'dtypes'\n",
    "    COUNT = 'count'\n",
    "\n",
    "COLUMN_RENAME_BY_DATASET = {\n",
    "    DataFramesCSV.WHO_OBESITY_CSV: {\n",
    "        'Numeric': 'percentage_obesity',\n",
    "        'Countries, territories and areas': 'country',\n",
    "        'WHO region': 'region',\n",
    "        'Year': 'year',\n",
    "    },\n",
    "    DataFramesCSV.HAPPINESS_REPORT_CSV: {\n",
    "        'year': 'year',\n",
    "        'Country name': 'country',\n",
    "        \"Life Ladder\": 'life_ladder',\n",
    "        \"Social support\": 'social_support',\n",
    "        \"Freedom to make life choices\": \"freedom_to_make_life_choices\",\n",
    "        \"Generosity\": \"generosity\",\n",
    "        \"Perceptions of corruption\": \"perceptions_of_corruption\",\n",
    "        \"Positive affect\": \"positive_affect\",\n",
    "        \"Negative affect\": \"negative_affect\",\n",
    "    },\n",
    "    DataFramesCSV.MEAT_CONSUMPTION_CSV: {\n",
    "        'Code': 'country_code',\n",
    "        'Year': 'year',\n",
    "        \"Meat, poultry | 00002734 || Food available for consumption | 0645pc || kilograms per year per capita\": \"poultry\",\n",
    "        \"Meat, beef | 00002731 || Food available for consumption | 0645pc || kilograms per year per capita\": \"beef\",\n",
    "        \"Meat, sheep and goat | 00002732 || Food available for consumption | 0645pc || kilograms per year per capita\": \"sheep_and_goat\",\n",
    "        \"Meat, pig | 00002733 || Food available for consumption | 0645pc || kilograms per year per capita\": \"pig\",\n",
    "        \"Fish and seafood | 00002960 || Food available for consumption | 0645pc || kilograms per year per capita\": \"fish_and_seafood\",\n",
    "    },\n",
    "    DataFramesCSV.COUNTRY_MASTER_CSV: {\n",
    "        'alpha-3': 'country_code',\n",
    "        'name': 'country'\n",
    "    },\n",
    "    DataFramesCSV.HUNGER_CSV: {\n",
    "        'Entity': 'country',\n",
    "        'Year': 'year',\n",
    "        'Global Hunger Index (2021)': 'hunger_index',\n",
    "    },\n",
    "    DataFramesCSV.SMOKING_CSV: {\n",
    "        'Entity': 'country',\n",
    "        'Year': 'year',\n",
    "        'Prevalence of current tobacco use (% of adults)': 'prevalence_smoking',\n",
    "    },\n",
    "    DataFramesCSV.ALCOHOL_CONSUMPTION_CSV: {\n",
    "        'Entity': 'country',\n",
    "        'Year': 'year',\n",
    "        'liters_of_pure_alcohol_per_capita': 'liters_of_pure_alcohol_per_capita',\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def capture_get_dataframe_info_image(\n",
    "        table_name: str,\n",
    "        name_file: str,\n",
    "        df_spark: pyspark.sql.dataframe.DataFrame,\n",
    "        previous_data: pd.Series = None,\n",
    "        previous_data_name: DataFramePreviousFieldNameOptions = None,\n",
    "        figure_size_height=10.0,\n",
    "        figure_size_width=5.0,\n",
    "):\n",
    "    dataframe = df_spark.toPandas()\n",
    "    info_object = {\n",
    "        'columns': dataframe.columns.str[0:30].tolist(),\n",
    "        'dtypes': dataframe.dtypes.tolist(),\n",
    "        'count': dataframe.count().tolist(),\n",
    "        'isnull': dataframe.isnull().sum().tolist(),\n",
    "    }\n",
    "    dataframe_info = pd.DataFrame(info_object)\n",
    "\n",
    "    if previous_data is not None:\n",
    "        current_data = dataframe_info[previous_data_name.value]\n",
    "        dataframe_info[f'old {previous_data_name.value}'] = previous_data\n",
    "        dataframe_info['change'] = previous_data - current_data\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(figure_size_width, figure_size_height))\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    dataframe_info.reset_index(inplace=True)\n",
    "    col_widths = [0.08, 0.35, 0.15, 0.15, 0.15, 0.15, 0.15]\n",
    "    data_table = ax.table(\n",
    "        cellText=dataframe_info.values,\n",
    "        colLabels=[' '.join(col.split('_')) for col in dataframe_info.columns],\n",
    "        colWidths=col_widths,\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    if previous_data is not None:\n",
    "        for (i, j), val in np.ndenumerate(dataframe_info.values):\n",
    "            if j == 6 and val != 0:  # We look into the second column (j==1), and search for zero values\n",
    "                data_table[(i + 1, j)].set_facecolor(\"red\")\n",
    "                data_table[(i + 1, j)].set_text_props(color='white', weight='bold')\n",
    "\n",
    "    num_rows = dataframe.shape[0] - 1\n",
    "    data_table.auto_set_font_size(False)\n",
    "    data_table.set_fontsize(6)\n",
    "    plt.title(f'{table_name} (Records: {num_rows})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PATH_IMAGES}{name_file}.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def capture_get_dataframe_info_image_new(\n",
    "        table_name: str,\n",
    "        name_file: str,\n",
    "        df_spark: pyspark.sql.dataframe.DataFrame,\n",
    "        previous_data: list = None,\n",
    "        previous_data_name: str = None,\n",
    "        figure_size_height=10.0,\n",
    "        figure_size_width=5.0,\n",
    "        PATH_IMAGES=\"./\"\n",
    "):\n",
    "\n",
    "    # Collect required statistics from PySpark DataFrame\n",
    "    column_names = [col[:30] for col in df_spark.columns]\n",
    "    column_types = [dtype for _, dtype in df_spark.dtypes]\n",
    "    row_count = df_spark.count()\n",
    "    column_counts = [row_count for _ in df_spark.columns]\n",
    "    column_null_counts = df_spark.agg(*[F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in df_spark.columns]).collect()[0]\n",
    "    column_non_null_counts = [row_count - null_count for null_count in column_null_counts]\n",
    "\n",
    "    info_object = {\n",
    "        'columns': column_names,\n",
    "        'dtypes': column_types,\n",
    "        'count': column_non_null_counts,\n",
    "        'isnull': column_null_counts\n",
    "    }\n",
    "\n",
    "    if previous_data is not None:\n",
    "        info_object[f'old {previous_data_name}'] = previous_data\n",
    "        current_data = info_object[previous_data_name]\n",
    "        info_object['change'] = [prev - curr for prev, curr in zip(previous_data, current_data)]\n",
    "\n",
    "    dataframe_info = list(zip(*info_object.values()))\n",
    "\n",
    "    # Plotting the table image\n",
    "    fig, ax = plt.subplots(figsize=(figure_size_width, figure_size_height))\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    col_widths = [0.08, 0.35, 0.15, 0.15, 0.15, 0.15, 0.15]\n",
    "    data_table = ax.table(\n",
    "        cellText=dataframe_info,\n",
    "        colLabels=[' '.join(col.split('_')) for col in info_object.keys()],\n",
    "        colWidths=col_widths,\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    if previous_data is not None:\n",
    "        for (i, j), val in np.ndenumerate(np.array(dataframe_info)):\n",
    "            if j == 6 and val != 0:  # We look into the last column (j==6), and search for non-zero values\n",
    "                data_table[(i + 1, j)].set_facecolor(\"red\")\n",
    "                data_table[(i + 1, j)].set_text_props(color='white', weight='bold')\n",
    "\n",
    "    num_rows = row_count - 1\n",
    "    data_table.auto_set_font_size(False)\n",
    "    data_table.set_fontsize(6)\n",
    "    plt.title(f'{table_name} (Records: {num_rows})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PATH_IMAGES}{name_file}.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def capture_summary_dataset_to_image(\n",
    "        name_file: str,\n",
    "        df_spark: pyspark.sql.dataframe.DataFrame,\n",
    "        dataset_name: str,\n",
    "        figure_size_height=3,\n",
    "        font_size=7,\n",
    "):\n",
    "    dataset = df_spark.toPandas()\n",
    "    desc = dataset.describe().round(2).T\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, figure_size_height))\n",
    "    new_order = ['min', '25%', '50%', '75%', 'max', 'mean', 'count', 'std']\n",
    "    desc = desc[new_order]\n",
    "    # Hide axes\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    col_widths = [0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08]\n",
    "\n",
    "    data_table = ax.table(\n",
    "        cellText=desc.values,\n",
    "        colLabels=desc.columns,\n",
    "        rowLabels=[name[:30] for name in desc.index],\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        colWidths=col_widths,\n",
    "    )\n",
    "    data_table.auto_set_font_size(False)\n",
    "    data_table.set_fontsize(font_size)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.title(f\"Descriptive Statistics {dataset_name}\")\n",
    "    plt.savefig(f\"{PATH_IMAGES}{name_file}.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def rename_columns(df, map_columns: Dict[str,str]) -> pyspark.sql.dataframe.DataFrame:\n",
    "    for old_name, new_name in map_columns.items():\n",
    "        df = df.withColumnRenamed(old_name, new_name)\n",
    "    return df\n",
    "\n",
    "def read_csv(file_path_enum: DataFramesCSV, sep=\",\") -> pyspark.sql.dataframe.DataFrame:\n",
    "    return spark.read.csv(file_path_enum.value, header=True, inferSchema=True, sep=sep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectManager:\n",
    "    missing_countries = None\n",
    "    country_master = None\n",
    "    integrated_dataset = None\n",
    "    generate_images_du_02: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        country_master = read_csv(DataFramesCSV.COUNTRY_MASTER_CSV)\n",
    "        country_master = rename_columns(\n",
    "            df=country_master,\n",
    "            map_columns={\n",
    "                \"alpha-3\": \"country_code\",\n",
    "                \"name\": \"country\"\n",
    "            }\n",
    "        )\n",
    "        self.country_master = country_master\n",
    "\n",
    "    def _capture_get_dataframe_info_image(\n",
    "            self,\n",
    "            table_name: str,\n",
    "            name_file: str,\n",
    "            df_spark: pyspark.sql.dataframe.DataFrame,\n",
    "            figure_size_height=10.0,\n",
    "            figure_size_width=5.0,\n",
    "            force_save_image=False,\n",
    "            previous_data: pd.Series = None,\n",
    "            previous_data_name: DataFramePreviousFieldNameOptions = None,\n",
    "    ):\n",
    "        if self.generate_images_du_02 or force_save_image:\n",
    "            capture_get_dataframe_info_image(\n",
    "                table_name=table_name,\n",
    "                name_file=name_file,\n",
    "                df_spark=df_spark,\n",
    "                figure_size_height=figure_size_height,\n",
    "                figure_size_width=figure_size_width,\n",
    "                previous_data_name=previous_data_name,\n",
    "                previous_data=previous_data,\n",
    "            )\n",
    "    \n",
    "    def _capture_summary_dataset_to_image(\n",
    "            self,\n",
    "            name_file: str,\n",
    "            df_spark: pyspark.sql.dataframe.DataFrame,\n",
    "            dataset_name: str,\n",
    "            figure_size_height=3,\n",
    "            font_size=7,\n",
    "    ):\n",
    "        if self.generate_images_du_02:\n",
    "            capture_summary_dataset_to_image(\n",
    "                name_file=name_file,\n",
    "                df_spark=df_spark,\n",
    "                dataset_name=dataset_name,\n",
    "                figure_size_height=figure_size_height,\n",
    "                font_size=font_size,\n",
    "            )\n",
    "\n",
    "    \n",
    "    def _du_02_country_master(self):\n",
    "        country_master = read_csv(DataFramesCSV.COUNTRY_MASTER_CSV)\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Countries Dataset',\n",
    "            name_file='du_country_dataset',\n",
    "            df_spark=country_master,\n",
    "            figure_size_height=2.5\n",
    "        )\n",
    "\n",
    "    def _du_02_meat_consumption(self):\n",
    "        meat_consumption = read_csv(DataFramesCSV.MEAT_CONSUMPTION_CSV)\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Meat Consumption Dataset',\n",
    "            name_file='du_meat_consumption_dataset',\n",
    "            df_spark=meat_consumption,\n",
    "            figure_size_height=2\n",
    "        )\n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=meat_consumption,\n",
    "            dataset_name='Meat Consumption',\n",
    "            name_file='du_meat_consumption_summary',\n",
    "            figure_size_height=2\n",
    "        )\n",
    "\n",
    "        meat_consumption = rename_columns(\n",
    "            df=meat_consumption,\n",
    "            map_columns=COLUMN_RENAME_BY_DATASET.get(DataFramesCSV.MEAT_CONSUMPTION_CSV)\n",
    "        )\n",
    "        \"\"\"\n",
    "        self._merge_by_country_code(dataset_name='meat_consumption', target_dataset=meat_consumption)\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=meat_consumption,\n",
    "            metric_name_plot='Kg./Year per Capita - Beef consumption',\n",
    "            metric_label='beef',\n",
    "            dataset_name='meat_beef',\n",
    "            country_label='country_code',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=meat_consumption,\n",
    "            metric_name_plot='Kg./Year per Capita - Poultry consumption',\n",
    "            metric_label='poultry',\n",
    "            dataset_name='meat_poultry',\n",
    "            country_label='country_code',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=meat_consumption,\n",
    "            metric_name_plot='Kg./Year per Capita - Sheep and Goat consumption',\n",
    "            metric_label='sheep_and_goat',\n",
    "            dataset_name='meat_sheep',\n",
    "            country_label='country_code',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=meat_consumption,\n",
    "            metric_name_plot='Kg./Year per Capita - Pig consumption',\n",
    "            metric_label='pig',\n",
    "            dataset_name='meat_pig',\n",
    "            country_label='country_code',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=meat_consumption,\n",
    "            metric_name_plot='Kg./Year per Capita - Fish and Seafood consumption',\n",
    "            metric_label='fish_and_seafood',\n",
    "            dataset_name='meat_fish_seafood',\n",
    "            country_label='country_code',\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def _du_02_hunger(self):\n",
    "        hunger = read_csv(DataFramesCSV.HUNGER_CSV)\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Hunger Dataset',\n",
    "            name_file='du_hunger_dataset',\n",
    "            df_spark=hunger,\n",
    "            figure_size_height=1.5\n",
    "        )\n",
    "        \n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=hunger,\n",
    "            dataset_name='Hunger',\n",
    "            name_file='du_hunger_summary',\n",
    "            figure_size_height=1\n",
    "        )\n",
    "        \"\"\"\n",
    "        hunger = hunger[[\"Entity\", \"Year\", \"Global Hunger Index (2021)\"]]\n",
    "        hunger.rename(\n",
    "            inplace=True,\n",
    "            columns=COLUMN_RENAME_BY_DATASET.get(DataFramesCSV.HUNGER_CSV)\n",
    "        )\n",
    "\n",
    "        self._merge_by_country_name(dataset_name='hunger', target_dataset=hunger)\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=hunger,\n",
    "            metric_name_plot='Global Hunger Index',\n",
    "            metric_label='hunger_index',\n",
    "            dataset_name='hunger',\n",
    "            country_label='country',\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def _du_02_smoking(self):\n",
    "        smoking = read_csv(DataFramesCSV.SMOKING_CSV)\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Smoking Dataset',\n",
    "            name_file='du_smoking_dataset',\n",
    "            df_spark=smoking,\n",
    "            figure_size_height=1\n",
    "        )\n",
    "        \n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=smoking,\n",
    "            dataset_name='Smoking',\n",
    "            name_file='du_smoking_summary',\n",
    "            figure_size_height=1\n",
    "        )\n",
    "        \"\"\"\n",
    "        smoking.drop(inplace=True, columns=[\"Code\"])\n",
    "        smoking.rename(\n",
    "            inplace=True,\n",
    "            columns=COLUMN_RENAME_BY_DATASET.get(DataFramesCSV.SMOKING_CSV)\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=smoking,\n",
    "            metric_name_plot='Percentage Prevalence Tobacco use Adults',\n",
    "            metric_label='prevalence_smoking',\n",
    "            dataset_name='smoking',\n",
    "        )\n",
    "        self._merge_by_country_name(dataset_name='smoking', target_dataset=smoking)\n",
    "        \"\"\"\n",
    "\n",
    "    def _du_02_alcohol_consumption(self):\n",
    "        alcohol_consumption = read_csv(DataFramesCSV.ALCOHOL_CONSUMPTION_CSV)\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Alcohol Consumption Dataset',\n",
    "            name_file='du_alcohol_consumption_dataset',\n",
    "            df_spark=alcohol_consumption,\n",
    "            figure_size_height=1.2\n",
    "        )\n",
    "        \n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=alcohol_consumption,\n",
    "            dataset_name='Alcohol Consumption',\n",
    "            name_file='du_alcohol_summary',\n",
    "            figure_size_height=1\n",
    "        )\n",
    "        \"\"\"\n",
    "        alcohol_consumption.drop(inplace=True, columns=[\"Code\"])\n",
    "\n",
    "        alcohol_consumption.rename(\n",
    "            inplace=True,\n",
    "            columns=COLUMN_RENAME_BY_DATASET.get(DataFramesCSV.ALCOHOL_CONSUMPTION_CSV)\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=alcohol_consumption,\n",
    "            metric_name_plot='Liters of Pure Alcohol per Capita',\n",
    "            metric_label='liters_of_pure_alcohol_per_capita',\n",
    "            dataset_name='alcohol',\n",
    "        )\n",
    "        self._merge_by_country_name(dataset_name='alcohol_consumption', target_dataset=alcohol_consumption)\n",
    "        \"\"\"\n",
    "    \n",
    "    def _du_02_obesity(self):\n",
    "        obesity_dataset = read_csv(DataFramesCSV.WHO_OBESITY_CSV)\n",
    "\n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=obesity_dataset,\n",
    "            dataset_name='obesity',\n",
    "            name_file='du_obesity_summary'\n",
    "        )\n",
    "\n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Obesity Dataset',\n",
    "            name_file='du_obesity_dataset',\n",
    "            df_spark=obesity_dataset,\n",
    "            figure_size_height=3.3\n",
    "        )\n",
    "        \"\"\"\n",
    "        # Sex if filtered to match both\n",
    "        obesity_dataset = obesity_dataset[obesity_dataset.Sex == \"Both sexes\"]\n",
    "        obesity_dataset = obesity_dataset[[\"Numeric\", \"Countries, territories and areas\", \"WHO region\", 'Year']]\n",
    "        obesity_dataset.rename(\n",
    "            inplace=True,\n",
    "            columns=pj.COLUMN_RENAME_BY_DATASET.get(pj.DataFramesCSV.WHO_OBESITY_CSV)\n",
    "        )\n",
    "\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=obesity_dataset,\n",
    "            metric_name_plot='Percentage Obesity',\n",
    "            metric_label='percentage_obesity',\n",
    "            dataset_name='obesity',\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def _du_02_happiness(self):\n",
    "        happiness_record = read_csv(DataFramesCSV.HAPPINESS_REPORT_CSV, sep=\";\")\n",
    "        \n",
    "        self._capture_get_dataframe_info_image(\n",
    "            table_name='Happiness Report Dataset',\n",
    "            name_file='du_happiness_dataset',\n",
    "            df_spark=happiness_record,\n",
    "            figure_size_height=2.5\n",
    "        )\n",
    "\n",
    "        self._capture_summary_dataset_to_image(\n",
    "            df_spark=happiness_record,\n",
    "            dataset_name='Happiness',\n",
    "            name_file='du_happiness_summary',\n",
    "            figure_size_height=2.3\n",
    "        )\n",
    "        \"\"\"\n",
    "        new_columns = [col.split(',', 2)[-1].strip() for col in happiness_record.columns]\n",
    "        happiness_record.columns = new_columns\n",
    "\n",
    "        happiness_record.rename(\n",
    "            inplace=True,\n",
    "            columns=COLUMN_RENAME_BY_DATASET.get(DataFramesCSV.HAPPINESS_REPORT_CSV)\n",
    "        )\n",
    "        self._merge_by_country_name(dataset_name='happiness', target_dataset=happiness_record)\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Life Ladder',\n",
    "            metric_label='life_ladder',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Social Support',\n",
    "            metric_label='social_support',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Freedom to Make Life Choices',\n",
    "            metric_label='freedom_to_make_life_choices',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Generosity',\n",
    "            metric_label='generosity',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Perceptions of Corruption',\n",
    "            metric_label='perceptions_of_corruption',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Positive Affect',\n",
    "            metric_label='positive_affect',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        self._du_data_exploration_basics(\n",
    "            dataset=happiness_record,\n",
    "            metric_name_plot='Negative affect',\n",
    "            metric_label='negative_affect',\n",
    "            dataset_name='happiness',\n",
    "            country_label='country',\n",
    "        )\n",
    "        \"\"\"\n",
    "    def _function_mapper_du_02(self, dataset: DataFramesCSV):\n",
    "        mapper = {\n",
    "            DataFramesCSV.MEAT_CONSUMPTION_CSV: self._du_02_meat_consumption,\n",
    "            DataFramesCSV.WHO_OBESITY_CSV: self._du_02_obesity,\n",
    "            DataFramesCSV.HAPPINESS_REPORT_CSV: self._du_02_happiness,\n",
    "            DataFramesCSV.HUNGER_CSV: self._du_02_hunger,\n",
    "            DataFramesCSV.SMOKING_CSV: self._du_02_smoking,\n",
    "            DataFramesCSV.ALCOHOL_CONSUMPTION_CSV: self._du_02_alcohol_consumption,\n",
    "        }\n",
    "\n",
    "        return mapper.get(dataset)\n",
    "    \n",
    "    def _du_02_run_processes(self):\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.MEAT_CONSUMPTION_CSV)()\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.WHO_OBESITY_CSV)()\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.HAPPINESS_REPORT_CSV)()\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.HUNGER_CSV)()\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.SMOKING_CSV)()\n",
    "        self._function_mapper_du_02(dataset=DataFramesCSV.ALCOHOL_CONSUMPTION_CSV)()\n",
    "\n",
    "    def du_02(self):\n",
    "        # pd.set_option('display.max_columns', None)\n",
    "        # pd.set_option('display.max_rows', None)\n",
    "        # pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        self._du_02_country_master()\n",
    "        self._du_02_run_processes()\n",
    "\n",
    "        # self.get_crosstab_missing_countries(save_table=True).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ProjectManager(\n",
    "    generate_images_du_02=True\n",
    ")\n",
    "# manager.country_master.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.du_02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = read_csv(DataFramesCSV.COUNTRY_MASTER_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columns': ['name', 'alpha-2', 'alpha-3', 'country-code', 'iso_3166-2', 'region', 'sub-region', 'intermediate-region', 'region-code', 'sub-region-code', 'intermediate-region-code'], 'dtypes': ['string', 'string', 'string', 'int', 'string', 'string', 'string', 'string', 'int', 'int', 'int'], 'count': [249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249], 'isnull': Row(name=0, alpha-2=0, alpha-3=0, country-code=0, iso_3166-2=0, region=1, sub-region=1, intermediate-region=142, region-code=1, sub-region-code=1, intermediate-region-code=142)}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "# Get column names truncated to 30 characters\n",
    "column_names = [col[:30] for col in df_spark.columns]\n",
    "\n",
    "# Get data types of columns\n",
    "column_types = [dtype for _, dtype in df_spark.dtypes]\n",
    "\n",
    "# Get count for each column\n",
    "row_count = df_spark.count()\n",
    "column_counts = [row_count for _ in df_spark.columns]\n",
    "\n",
    "# Get null count for each column\n",
    "column_null_counts = df_spark.agg(*[F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in df_spark.columns]).collect()[0]\n",
    "\n",
    "info_object = {\n",
    "    'columns': column_names,\n",
    "    'dtypes': column_types,\n",
    "    'count': column_counts,\n",
    "    'isnull': column_null_counts\n",
    "}\n",
    "\n",
    "print(info_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
